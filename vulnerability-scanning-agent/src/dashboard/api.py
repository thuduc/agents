#!/usr/bin/env python3
"""
REST API for vulnerability dashboard
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any

from aiohttp import web
from aiohttp.web_response import Response
from boto3.dynamodb.conditions import Attr

from ..core.models import Config
from ..storage.dynamodb_storage import DynamoDBStorage
from ..core.agent import VulnerabilityScanningAgent


class VulnerabilityDashboardAPI:
    """REST API for vulnerability dashboard and reporting"""
    
    def __init__(self, config: Config):
        self.config = config
        self.storage = DynamoDBStorage(config)
        self.app = web.Application()
        self._setup_routes()
        
    def _setup_routes(self):
        """Setup API routes"""
        self.app.router.add_get('/api/v1/dashboard', self.get_dashboard_summary)
        self.app.router.add_get('/api/v1/repositories', self.get_repositories)
        self.app.router.add_get('/api/v1/repositories/{repo}/vulnerabilities', self.get_repository_vulnerabilities)
        self.app.router.add_get('/api/v1/vulnerabilities/search', self.search_vulnerabilities)
        self.app.router.add_get('/api/v1/vulnerabilities/trending', self.get_trending_vulnerabilities)
        self.app.router.add_get('/api/v1/reports/executive', self.get_executive_report)
        self.app.router.add_get('/api/v1/metrics', self.get_security_metrics)
        self.app.router.add_post('/api/v1/scan/trigger', self.trigger_scan)
        self.app.router.add_get('/api/v1/scan/status', self.get_scan_status)
        self.app.router.add_get('/health', self.health_check)
        
        # WebSocket endpoint for real-time updates
        self.app.router.add_get('/ws/vulnerabilities', self.websocket_handler)
        
        # Static files for dashboard UI
        self.app.router.add_static('/', path='dashboard_ui', name='static')
    
    async def health_check(self, request: web.Request) -> web.Response:
        """Health check endpoint"""
        return web.json_response({
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'version': '1.0.0'
        })
    
    async def get_dashboard_summary(self, request: web.Request) -> web.Response:
        """Get high-level dashboard summary"""
        try:
            vulnerabilities = await self.storage.get_all_vulnerabilities()
            
            # Calculate summary statistics
            total_vulnerabilities = len(vulnerabilities)
            critical_count = len([v for v in vulnerabilities if v['severity'] == 'CRITICAL'])
            high_count = len([v for v in vulnerabilities if v['severity'] == 'HIGH'])
            medium_count = len([v for v in vulnerabilities if v['severity'] == 'MEDIUM'])
            low_count = len([v for v in vulnerabilities if v['severity'] == 'LOW'])
            
            # Repository statistics
            unique_repos = len(set(v['repository'] for v in vulnerabilities))
            
            # Top affected repositories
            repo_counts = {}
            for vuln in vulnerabilities:
                repo = vuln['repository']
                repo_counts[repo] = repo_counts.get(repo, 0) + 1
            
            top_repos = sorted(repo_counts.items(), key=lambda x: x[1], reverse=True)[:10]
            
            summary = {
                'total_vulnerabilities': total_vulnerabilities,
                'severity_breakdown': {
                    'critical': critical_count,
                    'high': high_count,
                    'medium': medium_count,
                    'low': low_count
                },
                'repositories_scanned': unique_repos,
                'top_affected_repositories': top_repos,
                'last_updated': datetime.now().isoformat()
            }
            
            return web.json_response(summary)
            
        except Exception as e:
            logging.error(f"Dashboard summary error: {e}")
            return web.json_response(
                {'error': 'Failed to generate dashboard summary'}, 
                status=500
            )
    
    async def get_repositories(self, request: web.Request) -> web.Response:
        """Get list of all scanned repositories with vulnerability counts"""
        try:
            vulnerabilities = await self.storage.get_all_vulnerabilities()
            
            # Group by repository
            repo_stats = {}
            for vuln in vulnerabilities:
                repo = vuln['repository']
                if repo not in repo_stats:
                    repo_stats[repo] = {
                        'repository': repo,
                        'total_vulnerabilities': 0,
                        'critical': 0,
                        'high': 0,
                        'medium': 0,
                        'low': 0,
                        'last_scan': None
                    }
                
                repo_stats[repo]['total_vulnerabilities'] += 1
                repo_stats[repo][vuln['severity'].lower()] += 1
                
                # Update last scan timestamp
                scan_time = datetime.fromisoformat(vuln['scan_timestamp'])
                if not repo_stats[repo]['last_scan'] or scan_time > datetime.fromisoformat(repo_stats[repo]['last_scan']):
                    repo_stats[repo]['last_scan'] = vuln['scan_timestamp']
            
            repositories = list(repo_stats.values())
            repositories.sort(key=lambda x: x['total_vulnerabilities'], reverse=True)
            
            return web.json_response({
                'repositories': repositories,
                'total_count': len(repositories)
            })
            
        except Exception as e:
            logging.error(f"Get repositories error: {e}")
            return web.json_response(
                {'error': 'Failed to fetch repositories'}, 
                status=500
            )
    
    async def get_repository_vulnerabilities(self, request: web.Request) -> web.Response:
        """Get vulnerabilities for a specific repository"""
        try:
            repo_name = request.match_info['repo']
            severity_filter = request.query.get('severity')
            limit = int(request.query.get('limit', 100))
            offset = int(request.query.get('offset', 0))
            
            vulnerabilities = await self.storage.get_repository_vulnerabilities(
                repo_name, severity_filter
            )
            
            # Apply pagination
            total_count = len(vulnerabilities)
            vulnerabilities = vulnerabilities[offset:offset + limit]
            
            return web.json_response({
                'repository': repo_name,
                'vulnerabilities': vulnerabilities,
                'total_count': total_count,
                'offset': offset,
                'limit': limit
            })
            
        except Exception as e:
            logging.error(f"Get repository vulnerabilities error: {e}")
            return web.json_response(
                {'error': 'Failed to fetch repository vulnerabilities'}, 
                status=500
            )
    
    async def search_vulnerabilities(self, request: web.Request) -> web.Response:
        """Search vulnerabilities by various criteria"""
        try:
            query = request.query.get('q', '')
            severity = request.query.get('severity')
            package = request.query.get('package')
            cve_id = request.query.get('cve')
            limit = int(request.query.get('limit', 100))
            
            # Get all vulnerabilities and filter in memory for simplicity
            # In production, this should use proper DynamoDB filtering
            all_vulnerabilities = await self.storage.get_all_vulnerabilities()
            filtered_vulns = []
            
            for vuln in all_vulnerabilities:
                matches = True
                
                if query and query.lower() not in vuln.get('description', '').lower():
                    matches = False
                if severity and vuln.get('severity', '').upper() != severity.upper():
                    matches = False
                if package and vuln.get('package_name', '') != package:
                    matches = False
                if cve_id and vuln.get('cve_id', '') != cve_id:
                    matches = False
                    
                if matches:
                    filtered_vulns.append(vuln)
            
            # Apply limit
            vulnerabilities = filtered_vulns[:limit]
            
            return web.json_response({
                'vulnerabilities': vulnerabilities,
                'count': len(vulnerabilities),
                'total_matches': len(filtered_vulns),
                'query': {
                    'q': query,
                    'severity': severity,
                    'package': package,
                    'cve': cve_id
                }
            })
            
        except Exception as e:
            logging.error(f"Search vulnerabilities error: {e}")
            return web.json_response(
                {'error': 'Failed to search vulnerabilities'}, 
                status=500
            )
    
    async def get_trending_vulnerabilities(self, request: web.Request) -> web.Response:
        """Get trending vulnerabilities over time"""
        try:
            days = int(request.query.get('days', 30))
            
            vulnerabilities = await self.storage.get_all_vulnerabilities()
            
            # Filter by date range
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            recent_vulns = [
                v for v in vulnerabilities 
                if start_date <= datetime.fromisoformat(v['scan_timestamp']) <= end_date
            ]
            
            # Group by date and severity
            daily_stats = {}
            for vuln in recent_vulns:
                scan_date = datetime.fromisoformat(vuln['scan_timestamp']).date()
                date_str = scan_date.isoformat()
                
                if date_str not in daily_stats:
                    daily_stats[date_str] = {
                        'date': date_str,
                        'total': 0,
                        'critical': 0,
                        'high': 0,
                        'medium': 0,
                        'low': 0
                    }
                
                daily_stats[date_str]['total'] += 1
                daily_stats[date_str][vuln['severity'].lower()] += 1
            
            # Sort by date
            trending_data = sorted(daily_stats.values(), key=lambda x: x['date'])
            
            return web.json_response({
                'trending_data': trending_data,
                'period_days': days,
                'start_date': start_date.isoformat(),
                'end_date': end_date.isoformat()
            })
            
        except Exception as e:
            logging.error(f"Get trending vulnerabilities error: {e}")
            return web.json_response(
                {'error': 'Failed to fetch trending data'}, 
                status=500
            )
    
    async def get_executive_report(self, request: web.Request) -> web.Response:
        """Generate executive-level security report"""
        try:
            vulnerabilities = await self.storage.get_all_vulnerabilities()
            
            # Calculate key metrics
            total_vulns = len(vulnerabilities)
            critical_vulns = len([v for v in vulnerabilities if v['severity'] == 'CRITICAL'])
            
            # Risk score calculation (weighted by severity)
            risk_score = 0
            for vuln in vulnerabilities:
                severity_weights = {
                    'CRITICAL': 10,
                    'HIGH': 7,
                    'MEDIUM': 4,
                    'LOW': 1
                }
                risk_score += severity_weights.get(vuln['severity'], 0)
            
            # Top vulnerable packages
            package_counts = {}
            for vuln in vulnerabilities:
                pkg = vuln['package_name']
                package_counts[pkg] = package_counts.get(pkg, 0) + 1
            
            top_packages = sorted(package_counts.items(), key=lambda x: x[1], reverse=True)[:10]
            
            # Remediation recommendations
            recommendations = []
            if critical_vulns > 0:
                recommendations.append({
                    'priority': 'HIGH',
                    'action': f'Immediate remediation required for {critical_vulns} critical vulnerabilities',
                    'timeline': '24-48 hours'
                })
            
            if total_vulns > 100:
                recommendations.append({
                    'priority': 'MEDIUM',
                    'action': 'Implement automated dependency update process',
                    'timeline': '1-2 weeks'
                })
            
            executive_report = {
                'report_date': datetime.now().isoformat(),
                'period': '90 days',
                'executive_summary': {
                    'total_vulnerabilities': total_vulns,
                    'critical_vulnerabilities': critical_vulns,
                    'overall_risk_score': risk_score,
                    'repositories_affected': len(set(v['repository'] for v in vulnerabilities))
                },
                'top_vulnerable_packages': top_packages,
                'recommendations': recommendations,
                'trend_analysis': 'Quarterly vulnerability trend analysis'
            }
            
            return web.json_response(executive_report)
            
        except Exception as e:
            logging.error(f"Executive report error: {e}")
            return web.json_response(
                {'error': 'Failed to generate executive report'}, 
                status=500
            )
    
    async def get_security_metrics(self, request: web.Request) -> web.Response:
        """Get detailed security metrics"""
        try:
            vulnerabilities = await self.storage.get_all_vulnerabilities()
            
            # Calculate various metrics
            metrics = {
                'vulnerability_density': {
                    'total_vulnerabilities': len(vulnerabilities),
                    'unique_cves': len(set(v['cve_id'] for v in vulnerabilities if v['cve_id'])),
                    'affected_repositories': len(set(v['repository'] for v in vulnerabilities))
                },
                'severity_distribution': {
                    'critical': len([v for v in vulnerabilities if v['severity'] == 'CRITICAL']),
                    'high': len([v for v in vulnerabilities if v['severity'] == 'HIGH']),
                    'medium': len([v for v in vulnerabilities if v['severity'] == 'MEDIUM']),
                    'low': len([v for v in vulnerabilities if v['severity'] == 'LOW'])
                },
                'source_breakdown': {},
                'average_cvss_score': 0,
                'latest_scan_date': None
            }
            
            # Source breakdown
            for vuln in vulnerabilities:
                source = vuln.get('source', 'UNKNOWN')
                metrics['source_breakdown'][source] = metrics['source_breakdown'].get(source, 0) + 1
            
            # Average CVSS score
            cvss_scores = [float(v['cvss_score']) for v in vulnerabilities if v.get('cvss_score')]
            if cvss_scores:
                metrics['average_cvss_score'] = sum(cvss_scores) / len(cvss_scores)
            
            # Latest scan date
            scan_dates = [datetime.fromisoformat(v['scan_timestamp']) for v in vulnerabilities]
            if scan_dates:
                metrics['latest_scan_date'] = max(scan_dates).isoformat()
            
            return web.json_response(metrics)
            
        except Exception as e:
            logging.error(f"Security metrics error: {e}")
            return web.json_response(
                {'error': 'Failed to fetch security metrics'}, 
                status=500
            )
    
    async def trigger_scan(self, request: web.Request) -> web.Response:
        """Trigger a new vulnerability scan"""
        try:
            data = await request.json()
            repository = data.get('repository')  # Optional: scan specific repo
            
            # Create and initialize scanner
            agent = VulnerabilityScanningAgent(self.config)
            await agent.initialize()
            
            # Start scan in background
            asyncio.create_task(agent.scan_all_repositories())
            
            return web.json_response({
                'message': 'Scan triggered successfully',
                'scan_id': f"scan_{int(datetime.now().timestamp())}",
                'status': 'running',
                'repository': repository
            })
            
        except Exception as e:
            logging.error(f"Trigger scan error: {e}")
            return web.json_response(
                {'error': 'Failed to trigger scan'}, 
                status=500
            )
    
    async def get_scan_status(self, request: web.Request) -> web.Response:
        """Get status of running scans"""
        try:
            return web.json_response({
                'active_scans': 0,
                'last_completed_scan': datetime.now().isoformat(),
                'status': 'idle'
            })
            
        except Exception as e:
            logging.error(f"Get scan status error: {e}")
            return web.json_response(
                {'error': 'Failed to fetch scan status'}, 
                status=500
            )
    
    async def websocket_handler(self, request: web.Request) -> web.WebSocketResponse:
        """WebSocket handler for real-time vulnerability updates"""
        ws = web.WebSocketResponse()
        await ws.prepare(request)
        
        try:
            # Send initial data
            await ws.send_str(json.dumps({
                'type': 'connected',
                'message': 'Connected to vulnerability updates stream'
            }))
            
            # Keep connection alive and send periodic updates
            while not ws.closed:
                await asyncio.sleep(30)
                
                # Send heartbeat
                await ws.send_str(json.dumps({
                    'type': 'heartbeat',
                    'timestamp': datetime.now().isoformat()
                }))
                
        except Exception as e:
            logging.error(f"WebSocket error: {e}")
        
        return ws
    
    def run(self, host='0.0.0.0', port=8080):
        """Run the dashboard API server"""
        logging.info(f"Starting vulnerability dashboard API on {host}:{port}")
        web.run_app(self.app, host=host, port=port)